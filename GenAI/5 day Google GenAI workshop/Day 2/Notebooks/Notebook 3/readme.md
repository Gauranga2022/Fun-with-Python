# ğŸ§  Day 2 - Classifying Embeddings with Keras and Gemini API

This notebook is part of the Kaggle Generative AI course. It teaches you how to use **text embeddings** generated by the **Gemini API** and train a **neural network classifier using Keras** to categorize news articles.

---

## ğŸ¯ Goal

Train a machine learning model to classify text documents into categories â€” **without** using raw text directly. Instead, use **embeddings** (numerical representations of meaning) as input.

---

## ğŸ“¦ What Youâ€™ll Do

### 1. **Install and Set Up**
- Install required libraries: `google-genai` (Gemini API).
- Remove any conflicting packages.
- Set up your API key securely using Kaggle Secrets.

### 2. **Get the Dataset**
- Use the **20 Newsgroups** dataset.
- It includes thousands of text posts from 20 different categories (like tech, politics, sports, etc.).

### 3. **Create Embeddings**
- Use the **Gemini API** to convert each post into an embedding (a list of numbers representing its meaning).

### 4. **Build a Classifier with Keras**
- Create a neural network using **Keras**.
- Train it on the embeddings to predict the category of each post.

### 5. **Evaluate the Model**
- Test how well the model performs on unseen data.
- Use metrics like **accuracy** to see how good the classifier is.

---

## ğŸ§  Why This Is Cool

- You donâ€™t have to train a model on raw text from scratch.
- Gemini embeddings already capture the meaning of the text.
- You can build a good classifier **faster** and with **less data**.

---

## ğŸ” Real-World Use Case

Instead of tagging every customer email manually:
- Convert the text into embeddings.
- Train a model like this to classify them (e.g., "support", "billing", "sales").

---

## ğŸ” Tip

Make sure your `GOOGLE_API_KEY` is saved in Kaggle Secrets and enabled for the notebook, or the Gemini API wonâ€™t work.

